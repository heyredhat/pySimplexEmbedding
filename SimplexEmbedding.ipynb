{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60ac9d6a",
   "metadata": {},
   "source": [
    "# Simplex embedding \n",
    "\n",
    "https://arxiv.org/abs/2204.11905"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f365058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import cvxpy as cp\n",
    "import cdd\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e66de53",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98aadcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For converting from density matrices/POVM elements to state/effect vectors.\n",
    "\n",
    "def gellmann_basis(d):\n",
    "    def h_helper(d,k):\n",
    "        if k == 1:\n",
    "            return np.eye(d)\n",
    "        if k > 1 and k < d:\n",
    "            return sc.linalg.block_diag(h_helper(d-1, k), [0])\n",
    "        if k == d:\n",
    "            return np.sqrt(2/(d*(d+1)))*sc.linalg.block_diag(np.eye(d-1), [1-d])\n",
    "\n",
    "    E = [[np.zeros((d,d)) for k in range(d)] for j in range(d)]\n",
    "    for j in range(d):\n",
    "        for k in range(d):\n",
    "            E[j][k][j,k] = 1\n",
    "    F = []\n",
    "    for j in range(d):\n",
    "        for k in range(d):\n",
    "            if k < j:\n",
    "                F.append(E[k][j] + E[j][k])\n",
    "            elif k > j:\n",
    "                F.append(-1j*(E[j][k] - E[k][j]))\n",
    "    F.extend([h_helper(d, k) for k in range(1,d+1)])\n",
    "    return np.array([f/np.sqrt((f@f).trace()) for f in F])\n",
    "\n",
    "def hilbert_to_gpt(states, effects):\n",
    "    d = states[0].shape[0]\n",
    "    basis = gellmann_basis(d)\n",
    "    to_gellmann = lambda O: np.array([(O@b).trace() for b in basis[::-1]])\n",
    "    from_gellman = lambda o: sum([c*basis[d**2-i] for i, c in enumerate(o)])\n",
    "    return np.array([to_gellmann(o) for o in states]).T.real,\\\n",
    "           np.array([to_gellmann(o) for o in effects]).real,\\\n",
    "                     to_gellmann(np.eye(d)).real,\\\n",
    "                     to_gellmann(np.eye(d)/d).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafbef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example1_gpt():\n",
    "    Zup, Zdown = np.array([1,0]), np.array([0,1])\n",
    "    Xup, Xdown = np.array([1,1])/np.sqrt(2), np.array([1,-1])/np.sqrt(2)\n",
    "    s = [np.outer(s, s.conj()) for s in [Zup, Zdown, Xup, Xdown]]\n",
    "    e = [_/2 for _ in s]\n",
    "    return hilbert_to_gpt(s, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a9e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example2_gpt():\n",
    "    return np.array([[1,0,0,0],\\\n",
    "                     [0,1,0,0],\\\n",
    "                     [0,0,1,0],\\\n",
    "                     [0,0,0,1]]),\\\n",
    "           np.array([[1,1,0,0],\n",
    "                     [0,1,1,0],\\\n",
    "                     [0,0,1,1],\\\n",
    "                     [1,0,0,1]])/2,\\\n",
    "           np.array([1,1,1,1]),\\\n",
    "           np.mean(S, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53d6fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxworld_gpt():\n",
    "    return np.array([[1,1,0],\\\n",
    "                     [1,0,1],\\\n",
    "                     [1,-1,0],\\\n",
    "                     [1,0,-1]]).T,\\\n",
    "           np.array([[1,-1,-1],\\\n",
    "                     [1,1,-1],\\\n",
    "                     [1,1,1],\\\n",
    "                     [1,-1,1]])/4,\\\n",
    "           np.array([1,0,0]),\\\n",
    "           np.array([1,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a29199",
   "metadata": {},
   "source": [
    "## Simplicial Embedding Algorithm: Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8906469f",
   "metadata": {},
   "source": [
    "We begin with \n",
    "\n",
    "1. A matrix $\\textbf{S}$ whose columns are GPT states.\n",
    "2. A matrix $\\textbf{E}$ whose rows are GPT effects.\n",
    "3. A normalization functional $(I|$ such that $(I|S_i)=1 \\ \\forall i$.\n",
    "4. A maximally mixed state $|M)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "8b61a3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states:\n",
      "[[ 1  1  1  1]\n",
      " [ 1  0 -1  0]\n",
      " [ 0  1  0 -1]]\n",
      "\n",
      "effects:\n",
      "[[ 0.25 -0.25 -0.25]\n",
      " [ 0.25  0.25 -0.25]\n",
      " [ 0.25  0.25  0.25]\n",
      " [ 0.25 -0.25  0.25]]\n",
      "\n",
      "(I|: [1 0 0]\n",
      "\n",
      "|M): [1 0 0]\n"
     ]
    }
   ],
   "source": [
    "S, E, I, M = boxworld_gpt()\n",
    "print(\"states:\\n%s\\n\\neffects:\\n%s\\n\\n(I|: %s\\n\\n|M): %s\" % (S, E, I, M))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef16487",
   "metadata": {},
   "source": [
    "## Constructing the accessible fragment\n",
    "\n",
    "First, we're going to switch to a representation where the states and effects live in the smallest vector spaces that can fit them, respectively.\n",
    "\n",
    "Suppose we have a set of $n$ states in $\\mathbb{R}^d$ given as columns of a $d \\times n$ matrix $\\textbf{S}$.\n",
    "\n",
    "Suppose $\\textbf{S}$ is rank $r$. If we take the SVD, $\\textbf{S} = UDV^\\dagger$, then $D$ will be a diagonal matrix with the $r$ singular values along the diagonal followed by 0's. Moreover, the columns of $U$ form an orthonormal basis for the column space of $\\textbf{S}$. If we take the first $r$ columns of $U$ and transpose them, we obtain a matrix $\\blacktriangleleft_S$ such that\n",
    "\n",
    "\\begin{align}\n",
    "|s) = \\blacktriangleleft_S |S)\n",
    "\\end{align}\n",
    "\n",
    "where $s$ is an $r$ dimensional column vector which we'll call the *accessible state* corresponding to $|S)$. Moreover, let $\\blacktriangleright_S = \\blacktriangleleft_S^T$. Then:\n",
    "\n",
    "\\begin{align}\n",
    "|S) = \\blacktriangleright_S|s) = \\blacktriangleright_S \\blacktriangleleft_S |S)\n",
    "\\end{align}\n",
    "\n",
    "Whereas multiplying by $\\blacktriangleleft_S$ expands $|S)$ in the orthonormal basis, multiplying by $\\blacktriangleright_S$ takes a linear combination of the basis vectors weighted by the elements of $|s)$, which takes us back to where we began."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "id": "1f86f410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tinyfier(X):\n",
    "    U, D, V = np.linalg.svd(X)\n",
    "    r = np.isclose(D, 0).argmax(axis=0)\n",
    "    return U[:,:r if r != 0 else D.shape[0]].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "b595b530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|S0): [1 1 0]\n",
      "|s0): [1. 1. 0.]\n",
      "|S0): [1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "bigToSmallStates = tinyfier(S)\n",
    "\n",
    "print(\"|S0): %s\" % (S[:,0]))\n",
    "print(\"|s0): %s\" % (bigToSmallStates @ S[:,0]))\n",
    "print(\"|S0): %s\" % (bigToSmallStates.T @ bigToSmallStates @ S[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3422d845",
   "metadata": {},
   "source": [
    "Similarly, we'll find a matrix $\\blacktriangleright_E$ such that\n",
    "\n",
    "\\begin{align}\n",
    "(E| \\blacktriangleright_E = |e).\n",
    "\\end{align}\n",
    "\n",
    "But since $\\textbf{E}$ consists of the effects as rows, we'll transpose to make them columns, and then transpose the result to get $\\blacktriangleright_E$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "id": "0586c000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(E0|: [ 0.25 -0.25 -0.25]\n",
      "(e0|: [-0.25 -0.25  0.25]\n",
      "(E0|: [ 0.25 -0.25 -0.25]\n"
     ]
    }
   ],
   "source": [
    "bigToSmallEffects = tinyfier(E.T).T\n",
    "\n",
    "print(\"(E0|: %s\" % (E[0,:]))\n",
    "print(\"(e0|: %s\" % (E[0,:] @ bigToSmallEffects))\n",
    "print(\"(E0|: %s\" % (E[0,:] @ bigToSmallEffects @ bigToSmallEffects.T ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edff8625",
   "metadata": {},
   "source": [
    "### Bloch transform\n",
    "\n",
    "We now need to do a little pre-processing on our accessible states (and effects). We'd like them all to be in \"Bloch form\" i.e. with the first component being $(I|S)$, the \"traceful part,\" and the rest being the \"traceless part.\"\n",
    "\n",
    "In order to do this, we first form the projectors onto the traceful part and the traceless part:\n",
    "\n",
    "\\begin{align}\n",
    "\\Pi_1 = \\frac{|I)(I|}{(I|I)} && \\Pi_0 = I - \\Pi_1.\n",
    "\\end{align}\n",
    "\n",
    "We then project the states $\\textbf{S}$ into the traceless subspace:\n",
    "\n",
    "\\begin{align}\n",
    "\\textbf{S}_0 = \\Pi_0 \\textbf{S}.\n",
    "\\end{align}\n",
    "\n",
    "Just as before, when we were constructing the accessible fragment, we take the singular value decomposition of $\\textbf{S}_0 = U D V^\\dagger$, and use the first $r = \\text{rank}(\\textbf{S}_0)$ columns of $U$, transposed, to construct a matrix $\\blacktriangleleft$ which takes us from \"big states\" to \"small states.\" Then \n",
    "\n",
    "\\begin{align}\n",
    "|s)_0 = \\blacktriangleleft \\Pi_0 |S)\n",
    "\\end{align}\n",
    "\n",
    "We then stack the normalization functional $(I|$ atop this matrix to obtain our Bloch transformation $B_S$:\n",
    "\n",
    "\\begin{align}\n",
    "B_S|S) = \n",
    "\\begin{pmatrix}\n",
    "(I| \\\\\n",
    "\\blacktriangleleft \\Pi_0 \n",
    "\\end{pmatrix}|S) = \n",
    "\\begin{pmatrix} \n",
    "(I|S) \\\\ |s)_0\n",
    "\\end{pmatrix}\n",
    "\\end{align}\n",
    "\n",
    "Now the states have normalization functional $(1, 0, \\dots, 0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "9b17365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bloch_transform(I, S):\n",
    "    Iproj = np.outer(I,I)/(I@I)\n",
    "    notIproj = np.eye(I.shape[0]) - Iproj\n",
    "    U, D, V = np.linalg.svd(notIproj @ S)\n",
    "    r = np.isclose(D, 0).argmax(axis=0)\n",
    "    return np.vstack([I, (U[:,:r if r != 0 else D.shape[0]].T) @ notIproj])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cf9267",
   "metadata": {},
   "source": [
    "In our case, however, we don't want to use the original normalization functional and the original states, but their accessible versions, $(I|\\blacktriangleright_S$ and $\\blacktriangleleft_S\\textbf{S}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "id": "f4c18aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.],\n",
       "       [ 0.,  1.,  0., -1.],\n",
       "       [ 1.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BS = bloch_transform(I @ bigToSmallStates.T, bigToSmallStates @ S)\n",
    "BS @ bigToSmallStates @ S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bcb389",
   "metadata": {},
   "source": [
    "We'll then do the same thing for our accessible effects: $\\textbf{E} \\blacktriangleright_E$ and $\\blacktriangleleft_E |I)$. Of course, in order to use the same function, we'll transpose everything first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "id": "06c6fa77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25, -0.25, -0.25],\n",
       "       [ 0.25, -0.25,  0.25],\n",
       "       [ 0.25,  0.25,  0.25],\n",
       "       [ 0.25,  0.25, -0.25]])"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BE = bloch_transform((bigToSmallEffects.T @ I).T, (E @ bigToSmallEffects).T)\n",
    "E @ bigToSmallEffects @ BE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072e8773",
   "metadata": {},
   "source": [
    "### Putting it together\n",
    "\n",
    "On the one hand, we have our accessible effects in the Bloch representation $\\textbf{E}_A = \\textbf{E} \\blacktriangleright_E B_E$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "id": "a817b4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25, -0.25, -0.25],\n",
       "       [ 0.25, -0.25,  0.25],\n",
       "       [ 0.25,  0.25,  0.25],\n",
       "       [ 0.25,  0.25, -0.25]])"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EA = E @ bigToSmallEffects @ BE; EA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a763699d",
   "metadata": {},
   "source": [
    "On the other hand, we have our accessible states in the Bloch representation $\\textbf{S}_A = B_S \\blacktriangleleft_S \\textbf{S}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "id": "c782774d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.],\n",
       "       [ 0.,  1.,  0., -1.],\n",
       "       [ 1.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 758,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA = BS @ bigToSmallStates @ S; SA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6e98e",
   "metadata": {},
   "source": [
    "Naturally, we can recover the inner products by considering the \"accessible identity matrix\" $I_A$:\n",
    "\n",
    "\\begin{align}\n",
    "I_A =  B_E^{-1} \\blacktriangleleft_E I \\blacktriangleright_S B_S^{-1}\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "\\textbf{E}_A I_A \\textbf{S}_A = \\left[ \\textbf{E} \\blacktriangleright_E B_E\\right]\\left[ B_E^{-1} \\blacktriangleleft_E I \\blacktriangleright_S B_S^{-1}\\right] \\left[B_S \\blacktriangleleft_S \\textbf{S} \\right] = \\textbf{E} \\textbf{S}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "id": "3e88eaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IA = np.linalg.inv(BE) @ bigToSmallEffects.T @ bigToSmallStates.T @ np.linalg.inv(BS)\n",
    "np.allclose(EA @ IA @ SA, E @ S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bd99c3",
   "metadata": {},
   "source": [
    "## Duals\n",
    "\n",
    "In general, if we have a set of $n$ states, we can consider the state space consisting of the convex hull of those states as points. Now, a convex hull can be described in two equivalent ways:\n",
    "\n",
    "1. By its extreme points: its vertices.\n",
    "\n",
    "2. By a set of halfspace inequalities of in the standard form $a_i \\cdot x + b_i \\leq 0$, which can be gathered up into a single matrix equation $Ax + b \\leq 0$.\n",
    "\n",
    "Now this latter representation can be reformulated as:\n",
    "\\begin{align}\n",
    "-Ax - b &\\ge 0\\\\\n",
    "\\begin{pmatrix}\n",
    "-b & -A\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "1 \\\\x\n",
    "\\end{pmatrix} \n",
    "&\\ge 0\\\\\n",
    "\\begin{pmatrix}\n",
    "-b_0 & -a_{00} & \\dots & -a_{0r}\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots\\\\\n",
    "-b_m &  -a_{m0} & \\dots & -a_{mr}\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "1 \\\\x\n",
    "\\end{pmatrix} &\\ge0\\\\\n",
    "\\textbf{S}^{*} |S) = \\overline{\\textbf{E}}|S) &\\ge0\n",
    "\\end{align}\n",
    "\n",
    "We can interpret the rows of the matrix $\\textbf{S}^{*}$ as a set of effects: they are linear functionals that are non-negative on the states.  Indeed, this is the reason we want our states to be in Bloch form. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e5c2bc",
   "metadata": {},
   "source": [
    "### Special 2D case\n",
    "\n",
    "Finally, note in the case where our states are 2D, so that after the Bloch transformation, our states simply live on a line, we have, denoting $\\vec{s}$ the traceless components of our states\n",
    "\n",
    "\\begin{align}\n",
    " x &\\ge \\text{min}(\\vec{s}) \\Rightarrow x - \\text{min}(\\vec{s}) \\ge 0\\\\\n",
    " x &\\le \\text{max}(\\vec{s}) \\Rightarrow  -x + \\text{max}(\\vec{s}) \\ge 0\n",
    "\\end{align}\n",
    "\n",
    "so that $\\textbf{S}^*$ becomes the $2 \\times 2$ matrix in\n",
    "\n",
    "\\begin{align}\n",
    "\\begin{pmatrix}\n",
    "- \\text{min}(\\vec{s}) & 1 \\\\ \n",
    "\\text{max}(\\vec{s}) & -1 \n",
    "\\end{pmatrix} \n",
    "\\begin{pmatrix}1 \\\\ x\n",
    "\\end{pmatrix} \\ge 0\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "id": "eb97d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dualize_states(S, backend=\"cdd\"):\n",
    "    if backend == \"qhull\":\n",
    "        if S.shape[0] == 2:\n",
    "            return np.array([[-np.min(S[1:]), 1],[np.max(S[1:]), -1]])\n",
    "        hull = sc.spatial.ConvexHull(S.T[:,1:])\n",
    "        eq = hull.equations\n",
    "        A, b = eq[:,:-1], eq[:, -1]\n",
    "        return -np.hstack([b.reshape(-1,1), A])\n",
    "    elif backend == \"cdd\":\n",
    "        C = cdd.Matrix(S.T, number_type=\"float\")\n",
    "        C.rep_type = cdd.RepType.GENERATOR\n",
    "        return np.array(cdd.Polyhedron(C).get_inequalities())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "id": "c6707c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.],\n",
       "       [ 1.,  1., -1.],\n",
       "       [ 1., -1., -1.],\n",
       "       [ 1., -1.,  1.]])"
      ]
     },
     "execution_count": 761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA_star = dualize_states(SA); SA_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "id": "a1e75e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  2., -0.,  0.],\n",
       "       [-0.,  2.,  2.,  0.],\n",
       "       [-0.,  0.,  2.,  2.],\n",
       "       [ 2.,  0., -0.,  2.]])"
      ]
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SA_star @ SA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0494a9c",
   "metadata": {},
   "source": [
    "Similarly, given a set of effects, we can consider the intersection of the halfspace inequalities they encode. The intersection points themselves form the extreme points of a convex body which is, dually, a state space. Arranging these into the columns of a matrix $\\textbf{E}^*$, we have:\n",
    "\n",
    "\\begin{align}\n",
    "(E| \\textbf{E}^* = (E|\\overline{\\textbf{S}} \\ge 0.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4a606b",
   "metadata": {},
   "source": [
    "In the 2D case, we have simply\n",
    "\n",
    "$$ \n",
    "\\begin{pmatrix}\n",
    "b_0 & a_0 \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "b_n & a_n\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix} \n",
    "1 & 1 \\\\\n",
    "x & y\n",
    "\\end{pmatrix} \\ge 0$$\n",
    "\n",
    "and we demand that $\\forall i, a_ix + b_i \\ge 0$. This leads to $x \\ge -\\frac{b_i}{a_i}$ if $a_i > 0$ and $x \\le -\\frac{b_i}{a_i}$ if $a_i < 0$. Thus we can take $x = \\text{max}(-\\frac{b_i}{a_i})$ among the $a_i > 0$ and $y = \\text{min}(-\\frac{b_i}{a_i})$ among the $a_i < 0$. \n",
    "\n",
    "If $\\forall i, a_i > 0$, then trivially we can take the column to be $(0, 1)$, since $(b_i, a_i) \\cdot (0,1) = a_i > 0$. Similarly, if $\\forall i, a_i < 0$, we can take the column to be $(1,0)$, since $(b_i, a_i) \\cdot (0,-1) = -a_i > 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "id": "f9e09707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interior_point(halfspaces):\n",
    "    #https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.HalfspaceIntersection.html\n",
    "    norm_vector = np.reshape(np.linalg.norm(halfspaces[:, :-1], axis=1), (halfspaces.shape[0], 1))\n",
    "    c = np.zeros((halfspaces.shape[1],)); c[-1] = -1\n",
    "    A = np.hstack((halfspaces[:, :-1], norm_vector))\n",
    "    b = -halfspaces[:, -1:]\n",
    "    res = sc.optimize.linprog(c, A_ub=A, b_ub=b, bounds=(None, None), method='highs')\n",
    "    if res.success:\n",
    "        return res.x[:-1]\n",
    "    else:\n",
    "        return np.zeros((halfspaces.shape[1]-1,))\n",
    "\n",
    "def dualize_effects(E, backend=\"cdd\"):\n",
    "    if backend == \"qhull\":\n",
    "        if E.shape[1] == 2:\n",
    "            b, a = E[:,0], E[:,1]\n",
    "            greater = [-b[i]/a[i] for i in range(len(a)) if a[i] > 0]\n",
    "            less = [-b[i]/a[i] for i in range(len(a)) if a[i] < 0]\n",
    "            return np.array([[1, np.max(greater)] if len(greater) != 0 else [0,-1],\\\n",
    "                             [1, np.min(less)] if len(less) != 0 else [0,1]]).T\n",
    "        hs = np.roll(-E, -1, axis=1)\n",
    "        half = sc.spatial.HalfspaceIntersection(hs, interior_point(hs))\n",
    "        intersections = half.intersections.T\n",
    "        return np.vstack([np.ones((1, intersections.shape[1])), intersections])\n",
    "    elif backend == \"cdd\":\n",
    "        C = cdd.Matrix(E, number_type=\"float\")\n",
    "        C.rep_type = cdd.RepType.INEQUALITY\n",
    "        return np.array(cdd.Polyhedron(C).get_generators()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "0295c233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1.,  1.],\n",
       "       [ 0.,  1.,  0., -1.],\n",
       "       [ 1.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 764,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EA_star = dualize_effects(EA); EA_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "dcb11b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0.5, 0.5],\n",
       "       [0.5, 0. , 0. , 0.5],\n",
       "       [0.5, 0.5, 0. , 0. ],\n",
       "       [0. , 0.5, 0.5, 0. ]])"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EA @ EA_star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032fe5d9",
   "metadata": {},
   "source": [
    "### qhull vs cddlib\n",
    "\n",
    "We provide two different backends for dualizing. It's worth noting that they use different conventions under the hood, although the functions `dualize_states` and `dualize_effects` automatically compensate for that.\n",
    "\n",
    " `scipy`'s `qhull` will find the convex hull of a set of points, but a) requires that we drop the traceful part of the states b) can't handle a 1D traceless part, which we handle separately. It encodes halfspaces in matrix form $Ax + b \\leq 0 \\Rightarrow [A; b]$. Similarly, `qhull` can find the intersection point of a set of halfspaces, except in the 1D case.\n",
    " \n",
    "`cddlib` can be fed in even the traceful parts: it takes vertices in the form $[t;  V]$, where the rows of $V$ are the vertices and $t=1$. (More generally, if $t=0$, that row is interpreted as a ray; and $t$ may actually be arbitrary.) It returns halfspace representations of the form $[b; -A]$ such that $Ax - b \\le 0$. It has no problem with the 1D case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5b90e6",
   "metadata": {},
   "source": [
    "In conclusion:\n",
    "\n",
    "1. We've found $\\textbf{E}_A^* = \\overline{\\textbf{S}}_A$, the dual of our accessible effects, such that $\\textbf{E}_A \\textbf{E}_A^* = \\textbf{E}_A \\overline{\\textbf{S}}_A \\ge 0$.\n",
    "\n",
    "2. We've found $\\textbf{S}_A^* = \\overline{\\textbf{E}}_A$, the dual of our accessible states, such that $\\textbf{S}_A^* \\textbf{S}_A  = \\overline{\\textbf{E}}_A \\textbf{S}_A \\ge 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed992b4d",
   "metadata": {},
   "source": [
    "## Simplicial Embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c12d1ac",
   "metadata": {},
   "source": [
    "Suppose we could find some $\\Phi$ such that\n",
    "\n",
    "\\begin{align}\n",
    "I_A &= \\textbf{E}^*_A \\Phi \\textbf{S}^*_A = \\overline{\\textbf{S}}_A  \\Phi \\overline{\\textbf{E}}_A.\n",
    "\\end{align}\n",
    "\n",
    "Then clearly\n",
    "\\begin{align}\n",
    "\\textbf{E}_A I_A \\textbf{S}_A &= \\textbf{E}_A \\overline{\\textbf{S}}_A  \\Phi \\overline{\\textbf{E}}_A   \\textbf{S}_A = \\textbf{ES}\n",
    "\\end{align}.\n",
    "\n",
    "Now by construction $\\textbf{E}_A \\overline{\\textbf{S}}_A \\ge 0$ and $\\overline{\\textbf{E}}_A   \\textbf{S}_A  \\ge 0$. Now if in addition, $\\Phi \\ge 0$, then:\n",
    "\n",
    "1. $\\textbf{E}_A \\overline{\\textbf{S}}_A  \\Phi = \\textbf{E} \\left[\\blacktriangleright_E B_E \\overline{\\textbf{S}}_A  \\Phi\\right] = \\textbf{E} \\tau_E  \\ge 0$\n",
    "2. $\\overline{\\textbf{E}}_A   \\textbf{S}_A  = \\left[\\overline{\\textbf{E}}_A B_S \\blacktriangleleft_S \\right] \\textbf{S} = \\tau_S \\textbf{S} \\ge0$\n",
    "3. $\\textbf{E} \\tau_E  \\tau_S \\textbf{S} = \\textbf{ES}$\n",
    "\n",
    "In other words, $\\tau_E$ and $\\tau_S$ realize a *simplicial embedding* of $\\textbf{E}$ and $\\textbf{S}$, which preserves all probabilities and repects convex combinations.\n",
    "\n",
    "The key here is that:\n",
    "\n",
    "1. $\\textbf{S}^*_A|s) \\ge 0$ if and only if $|s)$ is in the accessible state cone.\n",
    "\n",
    "2. Each row corresponds to a facet of the accessible state cone itself, or equivalently an extreme ray of the effect cone dual to the accessible state cone.\n",
    "\n",
    "3. Suppose we have *any effect* $(e|$ in the effect cone dual to the accessible state cone, i.e. any effect such that $(e|s) \\ge 0$ for all $|s)$ in the accessible state cone. Then since the rows of $\\textbf{S}^*_A$ form its extreme rays, any $(e|$ can be written as *some convex combination of the rows of $\\textbf{S}^*_A$*. In other words:\n",
    "\n",
    "$$ \\forall \\ (e|,\\exists \\ (e^\\prime|: (e| = (e^\\prime| \\textbf{S}^*_A = (e^\\prime| \\overline{\\textbf{E}}_A  $$\n",
    "\n",
    "where $(e^\\prime| \\ge 0$, elementwise.\n",
    "\n",
    "Similarly, we have $(e|\\textbf{E}^*_A \\ge 0$ iff $(e|$ is in the accessible effect cone. And any $|s)$ which is non-negative on those effects can be written as a convex combination of the columns of $\\textbf{E}^*$:\n",
    "\n",
    "$$ \\forall \\ |s), \\exists |s^\\prime): |s) = \\textbf{E}^*_A |s^\\prime) = \\overline{\\textbf{S}}_A|s^\\prime)$$\n",
    "\n",
    "Thus it is sufficient to search over $\\Phi$'s in $\\overline{\\textbf{S}}\\Phi\\overline{\\textbf{E}}_A$ to find any possible simplicial embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b283ad0",
   "metadata": {},
   "source": [
    "### Relaxing the problem\n",
    "\n",
    "\n",
    "In case that such a positive $\\Phi$ can't be found, it is useful to consider a relaxation of the problem. Consider the depolarized identity\n",
    "\n",
    "\\begin{align}\n",
    "D = r |M)(M| + (1-r) I,\n",
    "\\end{align}\n",
    "\n",
    "in its accessible Bloch form. Indeed, note that\n",
    "\n",
    "\\begin{align}\n",
    "|M)(M|_A = B_E^{-1} \\blacktriangleleft_E |M)(M| \\blacktriangleright_S B_S^{-1}\n",
    "\\end{align}\n",
    "\n",
    "where recall that $|M)$ is the maximally mixed state. So:\n",
    "\n",
    "\\begin{align}\n",
    "D_A = r |M)(M|_A  + (1-r)I_A.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "72bc950e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MA = np.linalg.inv(BE) @ bigToSmallEffects.T @ np.outer(M, M) @ bigToSmallStates.T @ np.linalg.inv(BS)\n",
    "np.allclose(EA @ MA @ SA, E @ np.outer(M,M) @ S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb92f245",
   "metadata": {},
   "source": [
    "We then want to find the positive $\\Phi$ such that\n",
    "\n",
    "\\begin{align}\n",
    "p|M)(M|_A + (1-p)I_A &= \\overline{\\textbf{S}}  \\Phi \\overline{\\textbf{E}}.\n",
    "\\end{align}\n",
    "\n",
    "for the minimum value of the depolarizing parameter $p$. If $p=0$, then we recover our original expression. Otherwise:\n",
    "\\begin{align}\n",
    "\\textbf{E}_A\\overline{\\textbf{S}}  \\Phi \\overline{\\textbf{E}}\\textbf{S}_A &= \\textbf{E}_A \\left[ p|M)(M|_A + (1-p)I_A\\right]\\textbf{S}_A \\\\\n",
    "&= p \\textbf{E}_A |M)(M|_A \\textbf{S}_A + (1-p) \\textbf{E}_A I_A \\textbf{S}_A\n",
    "\\end{align}\n",
    "\n",
    "Note:\n",
    "\n",
    "\\begin{align}\n",
    "\\textbf{E}_A |M)(M|_A \\textbf{S}_A &= \\left[\\textbf{E} \\blacktriangleright_E B_E \\right] \\left[ B_E^{-1} \\blacktriangleleft_E |M)(M| \\blacktriangleright_S B_S^{-1} \\right] \\left[ B_S \\blacktriangleleft_S \\textbf{S} \\right]\\\\\n",
    "&= \\textbf{E} |M)(M| \\textbf{S}\n",
    "\\end{align}\n",
    "\n",
    "So:\n",
    "\n",
    "\\begin{align}\n",
    "\\textbf{E}_A\\overline{\\textbf{S}}  \\Phi \\overline{\\textbf{E}}\\textbf{S}_A &=  p \\textbf{E} |M)(M| \\textbf{S} + (1-p) \\textbf{ES}\\\\\n",
    "&= \\textbf{E} \\left[ p|M)(M| + (1-p) I \\right] \\textbf{S}\\\\\n",
    "&= \\textbf{E} \\mathcal{D}(\\textbf{S})\n",
    "\\end{align}\n",
    "\n",
    "where $\\mathcal{D}(\\cdot) $ is the depolarizing map. Thus we can imagine depolarizing the states, shrinking them towards the maximally mixed state, while keeping the effects fixed, until a simplicial embedding is possible. (Of course, we could also equivalently consider depolarizing the effects.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "e66628a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplicial_embedding(S, E, IA, MA):\n",
    "    p_, Phi_ = cp.Variable(nonneg=True),\\\n",
    "               cp.Variable(shape=(S.shape[1], E.shape[0]), nonneg=True)\n",
    "    problem = cp.Problem(cp.Minimize(p_),\\\n",
    "               [p_*MA + (1-p_)*IA - S @ Phi_ @ E == 0])\n",
    "    problem.solve()\n",
    "    return p_.value, Phi_.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "222f6eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49999999936422973,\n",
       " array([[0.125, 0.   , 0.   , 0.125],\n",
       "        [0.125, 0.125, 0.   , 0.   ],\n",
       "        [0.   , 0.125, 0.125, 0.   ],\n",
       "        [0.   , 0.   , 0.125, 0.125]]))"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, Phi = simplicial_embedding(EA_star, SA_star, IA, MA); p, Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "0ab4d9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 769,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tauE = bigToSmallEffects @ BE @ EA_star @ Phi\n",
    "tauS = SA_star @ BS @ bigToSmallStates\n",
    "np.allclose(E @ tauE @ tauS @ S, E @ S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "37bd32eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.125, 0.125, 0.375, 0.375],\n",
       "        [0.375, 0.125, 0.125, 0.375],\n",
       "        [0.375, 0.375, 0.125, 0.125],\n",
       "        [0.125, 0.375, 0.375, 0.125]]),\n",
       " array([[0. , 0. , 0.5, 0.5],\n",
       "        [0.5, 0. , 0. , 0.5],\n",
       "        [0.5, 0.5, 0. , 0. ],\n",
       "        [0. , 0.5, 0.5, 0. ]]))"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E @ tauE @ tauS @ S, E @ S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "f4f004d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.   ,  0.063,  0.125,  0.063],\n",
       "        [ 0.063, -0.   ,  0.063,  0.125],\n",
       "        [ 0.125,  0.063,  0.   ,  0.063],\n",
       "        [ 0.063,  0.125,  0.063, -0.   ]]),\n",
       " array([[2., 2., 0., 0.],\n",
       "        [0., 2., 2., 0.],\n",
       "        [0., 0., 2., 2.],\n",
       "        [2., 0., 0., 2.]]))"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E @ tauE, tauS @ S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660810de",
   "metadata": {},
   "source": [
    "## Simplex Embedding\n",
    "\n",
    "Finally, we need to convert our simplicial embedding into a simplex embedding proper. \n",
    "\n",
    "To do this, we rescale the rows of $\\tau_S$ by the normalization on the columns of $\\tau_E$: this gives us $\\sigma_S$. We also need to rescale the columns of $\\tau_E$ by the inverse of the same: this gives us $\\sigma_E$. If the normalization is 0, then we drop the row and column.\n",
    "\n",
    "The point is that we need:\n",
    "\n",
    "$$(I|\\sigma_E = (1,\\dots,1) $$\n",
    "\n",
    "where the RHS is the normalization functional for the simplex GPT. Clearly, when we hit the columns $\\sigma_E$ with $(I|$, we'll get all 1's, since we divided the column of $\\tau_E$ by $(I|c_i)$, where $c_i$ is the $i$th column. We have to rescale $\\tau_S$ inversely to preserve probabilities, and hence we get $\\sigma_S$. We can't divide by 0, so we drop that row/column pair: this just means we have an extra ontic state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "e8ebf065",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmaS = np.array([tauS[i,:]*(I @ tauE[:,i]) for i in range(tauS.shape[0])\\\n",
    "                  if not np.isclose((I @ tauE[:,i]),0)])\n",
    "sigmaE = np.array([tauE[:,i]/(I @ tauE[:,i]) for i in range(tauE.shape[1])\\\n",
    "                  if not np.isclose((I @ tauE[:,i]),0)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "371890f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.  ,  0.25,  0.5 ,  0.25],\n",
       "        [ 0.25, -0.  ,  0.25,  0.5 ],\n",
       "        [ 0.5 ,  0.25,  0.  ,  0.25],\n",
       "        [ 0.25,  0.5 ,  0.25, -0.  ]]),\n",
       " array([[0.5, 0.5, 0. , 0. ],\n",
       "        [0. , 0.5, 0.5, 0. ],\n",
       "        [0. , 0. , 0.5, 0.5],\n",
       "        [0.5, 0. , 0. , 0.5]]))"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PE, PS = E @ sigmaE, sigmaS @ S\n",
    "PE, PS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "b469523b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(PE @ PS, E @ S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "e2ec7ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.125, 0.125, 0.375, 0.375],\n",
       "        [0.375, 0.125, 0.125, 0.375],\n",
       "        [0.375, 0.375, 0.125, 0.125],\n",
       "        [0.125, 0.375, 0.375, 0.125]]),\n",
       " array([[0. , 0. , 0.5, 0.5],\n",
       "        [0.5, 0. , 0. , 0.5],\n",
       "        [0.5, 0.5, 0. , 0. ],\n",
       "        [0. , 0.5, 0.5, 0. ]]))"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PE @ PS, E @ S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "79344516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 1., 1., 1.]), array([1., 1., 1., 1.]))"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(PE, axis=0), np.sum(PS, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ce078e",
   "metadata": {},
   "source": [
    "## Finale\n",
    "\n",
    "In conclusion, let's gather everything up into a single function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702839d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplex_embedding(S, E, I, M, backend=\"cdd\"):\n",
    "    bigToSmallStates = tinyfier(S)\n",
    "    bigToSmallEffects = tinyfier(E.T).T\n",
    "    BS = bloch_transform(I @ bigToSmallStates.T, bigToSmallStates @ S)\n",
    "    BE = bloch_transform((bigToSmallEffects.T @ I).T, (E @ bigToSmallEffects).T)\n",
    "\n",
    "    EA = E @ bigToSmallEffects @ BE\n",
    "    SA = BS @ bigToSmallStates @ S\n",
    "    IA = np.linalg.inv(BE) @ bigToSmallEffects.T @ bigToSmallStates.T @ np.linalg.inv(BS)\n",
    "    MA = np.linalg.inv(BE) @ bigToSmallEffects.T @ np.outer(M, M) @ bigToSmallStates.T @ np.linalg.inv(BS)\n",
    "\n",
    "    SA_star = dualize_states(SA, backend=backend)\n",
    "    EA_star = dualize_effects(EA, backend=backend)\n",
    "    p, Phi = simplicial_embedding(EA_star, SA_star, IA, MA)\n",
    "\n",
    "    tauE = bigToSmallEffects @ BE @ EA_star @ Phi\n",
    "    tauS = SA_star @ BS @ bigToSmallStates\n",
    "    sigmaS = np.array([tauS[i,:]*(I @ tauE[:,i]) for i in range(tauS.shape[0])\\\n",
    "                  if not np.isclose((I @ tauE[:,i]),0)])\n",
    "    sigmaE = np.array([tauE[:,i]/(I @ tauE[:,i]) for i in range(tauE.shape[1])\\\n",
    "                  if not np.isclose((I @ tauE[:,i]),0)]).T\n",
    "\n",
    "    PE, PS = E @ sigmaE, sigmaS @ S\n",
    "    return p, PE, PS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a710e408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49999999936422973,\n",
       " array([[ 0.  ,  0.25,  0.5 ,  0.25],\n",
       "        [ 0.25, -0.  ,  0.25,  0.5 ],\n",
       "        [ 0.5 ,  0.25,  0.  ,  0.25],\n",
       "        [ 0.25,  0.5 ,  0.25, -0.  ]]),\n",
       " array([[0.5, 0.5, 0. , 0. ],\n",
       "        [0. , 0.5, 0.5, 0. ],\n",
       "        [0. , 0. , 0.5, 0.5],\n",
       "        [0.5, 0. , 0. , 0.5]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplex_embedding(*boxworld_gpt())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
